
\section{Introduction}
During software development it is natural to make mistakes. Consequently,
writing various test cases is required in order to validate the behavior
of the program. In addition to the costs of test writing, it is possible that the developers fail
to cover all possible critical cases. Furthermore, writing and executing
often happens late in the development cycle, but the costs of error correction
increases proportionally to elapsed time  \cite{fixcost}. This proves that 
testing alone is not necessarily sufficient to ensure code quality.  %Moreover,
%there are specific properties of a software - e.g. coding convention following 
%- which can not be checked by test cases.

The static analysis tools offer a different approach for code validation 
\cite{Zhivich2009} \cite{Bessey2010}, moreover, they can potentially check for 
some characteristics of the code -- which cannot be verified by testing -- e.g. 
the adherence to conventions.

These tools are given the source code as input, using which they build a model 
and make inferences based on that. The efficiency, accuracy, and runtime of the 
analysis changes depending on the complexity of the model.
The final output is a list of bug reports. However bugs are used quite 
liberally here; they do not necessarily imply program malfunctions, as 
optimizations or code convention nits are also included. Code chunks deemed 
fragile or to have potential portability problems are listed too, so there can 
be a wide variety of possible outputs.
This document focuses on static analysis primarily as a method of uncovering 
bugs.
 
Unfortunately, it is impossible to detect every 
bug only by using static analysis \cite{Rice:53}. Static analyzer tools might 
not be able to discover some bugs (these are called false negatives) or report 
correct code snippets as incorrect (false positives, see Fig \ref{fig:bes}). In 
the industry the goal of these tools is to keep the ratio of the false positive 
reports low while still be able to find real bugs.

\begin{figure}[!h]
	\begin{center}
		\begin{tabular}{ | l | c | r | }
			\hline
			& True error   & Non-error \\ \hline
			Reported error   & True Positive  & False Positive   \\ \hline
			No error report & False Negative & True Negative    \\
			\hline
		\end{tabular}
	\end{center}
	\caption{The different types of the static analysis results.}
	\label{fig:bes}
\end{figure}

Its important to note that another advantage of the static analyzer tools 
(against test systems) that the analysis happens without executing the source 
code, so it can be used without the runtime environment. Moreover, the code 
coverage of the analysis does not depends on the already written test case set 
and even can find bugs which is not covered by test cases e.g. unexpected 
corner cases on the input variables. 

The LLVM Clang Static Analyzer is a source code analysis tool which aims to 
find bugs in C,
C++, and Objective-C programs using - one of the most precise analysis methods 
- symbolic execution  \cite{King1975} \cite{Hampapuram2005}, i.e. it simulates 
the possible execution paths of the code. During symbolic execution, the 
program is being interpreted, on a function-by-function basis, without any 
knowledge about the runtime environment. It builds up and traverses an internal 
model of the execution paths, called \texttt{ExplodedGraph}, for each analyzed 
function. This method has exponential runtime and space complexity in the 
number of branches.

Thus, the Clang Static Analyzer is a great tool to validate our code base, 
however, it has some strict limitations on modeling loops. Currently the 
simulation of the loops is somewhat naive (but efficient), unrolling the loops 
a predefined constant number of times. This approach can result in a low 
analysis coverage in various cases and restrain the usage of the tool in 
industrial environments.
This study presents the principle of operation of the Clang Static Analyzer and 
demonstrates cases where its current loop modeling behavior leads to 
questionable results (false negatives) which can bring mistrust against the 
tool. Furthermore, this study aims to introduce two alternative approaches 
which can extend the current method and can be applied simultaneously: 
\begin{enumerate} [label={(\arabic*)}, noitemsep]
	\item determining loops worth to fully unroll with applied heuristics, and
	\item using a widening mechanism to simulate an arbitrary number of 
	iteration steps.
\end{enumerate}
These methods were evaluated on numerous open source projects, and 
 proved to increase coverage in all of the cases.
